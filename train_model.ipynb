{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "110266ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2441052",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CrowdDataset(Dataset):\n",
    "    def __init__(self, img_dir, den_dir):\n",
    "        self.img_dir = img_dir\n",
    "        self.den_dir = den_dir\n",
    "        self.img_files = sorted([f for f in os.listdir(img_dir) if f.endswith(\"_img.npy\")])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_files[idx]\n",
    "        den_name = img_name.replace(\"_img.npy\", \"_den.npy\")\n",
    "\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        den_path = os.path.join(self.den_dir, den_name)\n",
    "\n",
    "        img = np.load(img_path)\n",
    "        den = np.load(den_path)\n",
    "\n",
    "        img = torch.tensor(img, dtype=torch.float32)\n",
    "        den = torch.tensor(den, dtype=torch.float32).unsqueeze(0)  # (1,512,512)\n",
    "\n",
    "        # ðŸ”¥ FIX â€” downsample density map for CSRNet output\n",
    "        den = F.interpolate(den.unsqueeze(0), size=(64, 64), mode='nearest').squeeze(0)\n",
    "\n",
    "        return img, den\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1890ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_path = r\"C:\\Users\\sneha\\.cache\\kagglehub\\datasets\\tthien\\shanghaitech\\versions\\1\\ShanghaiTech\\part_A\\images_npy\"\n",
    "train_den_path = r\"C:\\Users\\sneha\\.cache\\kagglehub\\datasets\\tthien\\shanghaitech\\versions\\1\\ShanghaiTech\\part_A\\density_maps_npy\"\n",
    "\n",
    "dataset = CrowdDataset(train_img_path, train_den_path)\n",
    "train_loader = DataLoader(dataset, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c3dac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSRNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CSRNet, self).__init__()\n",
    "\n",
    "        self.frontend = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, 3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(256, 512, 3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, 3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, 3, padding=1), nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.backend = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, 3, dilation=2, padding=2), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, 3, dilation=2, padding=2), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 256, 3, dilation=2, padding=2), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 128, 3, dilation=2, padding=2), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 64, 3, dilation=2, padding=2), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 1, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.frontend(x)\n",
    "        x = self.backend(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9a862f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CSRNet().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6239df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [45:21<00:00,  9.07s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 0.0010\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [42:38<00:00,  8.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 0.0001\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [40:16<00:00,  8.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 0.0001\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 25/300 [02:28<27:17,  5.95s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m output = model(img)\n\u001b[32m     18\u001b[39m loss = criterion(output, den)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m optimizer.step()\n\u001b[32m     23\u001b[39m batch_losses.append(loss.item())\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Python Projects\\DeepVision\\myenv\\Lib\\site-packages\\torch\\_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Python Projects\\DeepVision\\myenv\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Python Projects\\DeepVision\\myenv\\Lib\\site-packages\\torch\\autograd\\graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "batch_losses = []\n",
    "epoch_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    pbar = tqdm(train_loader, ncols=120)\n",
    "\n",
    "    for batch_idx, (img, den) in enumerate(pbar):\n",
    "\n",
    "        # Move to device\n",
    "        img = img.to(device)\n",
    "        den = den.to(device)\n",
    "\n",
    "        # Forward + backward\n",
    "        optimizer.zero_grad()\n",
    "        output = model(img)\n",
    "        loss = criterion(output, den)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Logging\n",
    "        batch_losses.append(loss.item())\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # --- Update tqdm bar like Keras ---\n",
    "        pbar.set_postfix({\n",
    "            \"batch\": f\"{batch_idx+1}/{len(train_loader)}\",\n",
    "            \"loss\": f\"{loss.item():.4f}\"\n",
    "        })\n",
    "\n",
    "    # Compute avg loss\n",
    "    epoch_loss /= len(train_loader)\n",
    "    epoch_losses.append(epoch_loss)\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "          f\"loss: {epoch_loss:.4f} - \"\n",
    "          f\"time: {epoch_time:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd15e737",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"csrnet_partA_weights.pth\")\n",
    "print(\"Saved as csrnet_partA_weights.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b76325",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(batch_losses)\n",
    "plt.title(\"Batch Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(epoch_losses)\n",
    "plt.title(\"Epoch Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81d21107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Path to the folder containing IMG_{i}_img.npy and IMG_{i}_den.npy\n",
    "DATA_DIR = r\"C:\\Users\\sneha\\.cache\\kagglehub\\datasets\\tthien\\shanghaitech\\versions\\1\\ShanghaiTech\\part_A\\train_data\\processed\"   # <-- CHANGE this to your output_dir from preprocessing\n",
    "\n",
    "# training config\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 4         # reduce if OOM\n",
    "lr = 1e-5\n",
    "num_epochs = 50\n",
    "print_every = 20\n",
    "save_best_path = \"csrnet_best_partA.pth\"\n",
    "checkpoint_path = \"csrnet_checkpoint.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63d1b06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples found: 300\n",
      "Sample shapes: torch.Size([3, 512, 512]) torch.Size([1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "# Cell 2\n",
    "class CrowdNPYDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        # find image files using pattern\n",
    "        self.img_files = sorted([f for f in os.listdir(data_dir) if f.endswith(\"_img.npy\")])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_files[idx]\n",
    "        base = img_name.replace(\"_img.npy\", \"\")\n",
    "        img_path = os.path.join(self.data_dir, f\"{base}_img.npy\")\n",
    "        den_path = os.path.join(self.data_dir, f\"{base}_den.npy\")\n",
    "\n",
    "        img = np.load(img_path).astype(np.float32)          # expected (H,W,3) or (3,H,W)\n",
    "        den = np.load(den_path).astype(np.float32)          # expected (H_ds, W_ds) e.g., (64,64)\n",
    "\n",
    "        # If image is (H,W,3) -> convert to (3,H,W)\n",
    "        if img.ndim == 3 and img.shape[2] == 3:\n",
    "            img = img.transpose(2,0,1)\n",
    "\n",
    "        # Normalize image to 0-1\n",
    "        img = img / 255.0\n",
    "\n",
    "        img_t = torch.from_numpy(img).float()\n",
    "        den_t = torch.from_numpy(den).float().unsqueeze(0)   # (1, H_ds, W_ds)\n",
    "\n",
    "        return img_t, den_t\n",
    "\n",
    "# quick dataset sanity\n",
    "dataset = CrowdNPYDataset(DATA_DIR)\n",
    "print(\"Samples found:\", len(dataset))\n",
    "sample_img, sample_den = dataset[0]\n",
    "print(\"Sample shapes:\", sample_img.shape, sample_den.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0bddb8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created on cpu\n"
     ]
    }
   ],
   "source": [
    "# Cell 3\n",
    "import torchvision.models as models\n",
    "\n",
    "class CSRNet(nn.Module):\n",
    "    def __init__(self, load_pretrained_frontend=True):\n",
    "        super(CSRNet, self).__init__()\n",
    "        # use VGG16 frontend (features up to conv4_3)\n",
    "        vgg = models.vgg16(weights=None)\n",
    "        frontend_layers = list(vgg.features.children())[:23]  # up to conv4_3 pool\n",
    "        self.frontend = nn.Sequential(*frontend_layers)\n",
    "\n",
    "        # backend (dilated convs)\n",
    "        self.backend = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, 3, padding=2, dilation=2), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, 3, padding=2, dilation=2), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, 3, padding=2, dilation=2), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 256, 3, padding=2, dilation=2), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 128, 3, padding=2, dilation=2), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 64, 3, padding=2, dilation=2), nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.frontend(x)\n",
    "        x = self.backend(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# create model\n",
    "model = CSRNet().to(device)\n",
    "print(\"Model created on\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3efdfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 240, Val: 60\n"
     ]
    }
   ],
   "source": [
    "# Cell 4\n",
    "# split dataset (80/20)\n",
    "total = len(dataset)\n",
    "train_len = int(0.8 * total)\n",
    "val_len = total - train_len\n",
    "train_ds, val_ds = random_split(dataset, [train_len, val_len])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=1, pin_memory=True)\n",
    "\n",
    "print(f\"Train: {len(train_ds)}, Val: {len(val_ds)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b1fd1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "def count_from_density(tensor):\n",
    "    # tensor: numpy array or torch tensor\n",
    "    if isinstance(tensor, torch.Tensor):\n",
    "        return tensor.sum().item()\n",
    "    return np.sum(tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aff19bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   0%|                                                                                | 0/60 [00:00<?, ?it/s]d:\\Python Projects\\DeepVision\\myenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Epoch 1/50:   0%|                                                                                | 0/60 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 7940, 8680) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEmpty\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Python Projects\\DeepVision\\myenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1275\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1274\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1275\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\queues.py:114\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll(timeout):\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll():\n",
      "\u001b[31mEmpty\u001b[39m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m start = time.time()\n\u001b[32m     11\u001b[39m pbar = tqdm(train_loader, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, ncols=\u001b[32m120\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# (B,3,H,W)\u001b[39;49;00m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdens\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdens\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# (B,1,h,w) e.g. (B,1,64,64)\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Python Projects\\DeepVision\\myenv\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Python Projects\\DeepVision\\myenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Python Projects\\DeepVision\\myenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1482\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1479\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1481\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1482\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1483\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1484\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1485\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Python Projects\\DeepVision\\myenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1444\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1440\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1441\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1442\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1443\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1444\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1445\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1446\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Python Projects\\DeepVision\\myenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1288\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1286\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) > \u001b[32m0\u001b[39m:\n\u001b[32m   1287\u001b[39m     pids_str = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mstr\u001b[39m(w.pid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[32m-> \u001b[39m\u001b[32m1288\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1289\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) exited unexpectedly\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1290\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1291\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue.Empty):\n\u001b[32m   1292\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mRuntimeError\u001b[39m: DataLoader worker (pid(s) 7940, 8680) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "# Cell 6\n",
    "best_val_mae = float(\"inf\")\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    start = time.time()\n",
    "\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{num_epochs}\", ncols=120)\n",
    "    for batch_idx, (imgs, dens) in enumerate(pbar, 1):\n",
    "        imgs = imgs.to(device)            # (B,3,H,W)\n",
    "        dens = dens.to(device)            # (B,1,h,w) e.g. (B,1,64,64)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "\n",
    "        # if output and dens sizes don't match, resize outputs\n",
    "        if outputs.shape != dens.shape:\n",
    "            outputs = F.interpolate(outputs, size=dens.shape[2:], mode='bilinear', align_corners=False)\n",
    "\n",
    "        loss = criterion(outputs, dens)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        pbar.set_postfix({\"batch_loss\": f\"{loss.item():.6f}\"})\n",
    "\n",
    "    avg_train_loss = epoch_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation (MAE & val loss)\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    mae_sum = 0.0\n",
    "    rmse_sum = 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, dens in val_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            dens = dens.to(device)\n",
    "            preds = model(imgs)\n",
    "            if preds.shape != dens.shape:\n",
    "                preds = F.interpolate(preds, size=dens.shape[2:], mode='bilinear', align_corners=False)\n",
    "\n",
    "            val_loss += criterion(preds, dens).item()\n",
    "            # for counting, upsample patch to original ds size if needed â€” here both are ds\n",
    "            pred_count = preds.sum().item()\n",
    "            gt_count = dens.sum().item()\n",
    "            mae_sum += abs(pred_count - gt_count)\n",
    "            rmse_sum += (pred_count - gt_count)**2\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    MAE = mae_sum / len(val_loader)\n",
    "    RMSE = (rmse_sum / len(val_loader))**0.5\n",
    "\n",
    "    epoch_time = time.time() - start\n",
    "    print(f\"Epoch {epoch}/{num_epochs} - loss: {avg_train_loss:.6f} - val_loss: {avg_val_loss:.6f} - MAE: {MAE:.3f} - RMSE: {RMSE:.3f} - time: {epoch_time:.1f}s\")\n",
    "\n",
    "    # save checkpoint every epoch (optional) / save best\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optimizer_state\": optimizer.state_dict(),\n",
    "        \"train_losses\": train_losses,\n",
    "        \"val_losses\": val_losses,\n",
    "    }, checkpoint_path)\n",
    "\n",
    "    if MAE < best_val_mae:\n",
    "        best_val_mae = MAE\n",
    "        torch.save(model.state_dict(), save_best_path)\n",
    "        print(f\"Saved best model (MAE={best_val_mae:.3f}) -> {save_best_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c935d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "root = r\"C:\\Users\\sneha\\.cache\\kagglehub\\datasets\\tthien\\shanghaitech\\versions\\1\\ShanghaiTech\\part_A\\train_data\\processed\"\n",
    "\n",
    "for file in os.listdir(root):\n",
    "    if file.endswith(\".npy\"):\n",
    "        path = os.path.join(root, file)\n",
    "        try:\n",
    "            d = np.load(path)\n",
    "        except Exception as e:\n",
    "            print(\"Corrupted:\", path, e)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262f56eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mimg_tensor\u001b[49m.shape != (\u001b[32m3\u001b[39m, \u001b[32m512\u001b[39m, \u001b[32m512\u001b[39m):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBad image:\u001b[39m\u001b[33m\"\u001b[39m, img_path, img_tensor.shape)\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m density.shape != (\u001b[32m64\u001b[39m, \u001b[32m64\u001b[39m):\n",
      "\u001b[31mNameError\u001b[39m: name 'img_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d55c9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_losses, label=\"train_loss\")\n",
    "plt.plot(val_losses, label=\"val_loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"val\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"Loss curves\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61e93bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_100_img.npy: (3, 512, 512), IMG_100_den.npy: (1, 64, 64)\n",
      "IMG_101_img.npy: (3, 512, 512), IMG_101_den.npy: (1, 64, 64)\n",
      "IMG_102_img.npy: (3, 512, 512), IMG_102_den.npy: (1, 64, 64)\n",
      "IMG_103_img.npy: (3, 512, 512), IMG_103_den.npy: (1, 64, 64)\n",
      "IMG_104_img.npy: (3, 512, 512), IMG_104_den.npy: (1, 64, 64)\n",
      "IMG_105_img.npy: (3, 512, 512), IMG_105_den.npy: (1, 64, 64)\n",
      "IMG_106_img.npy: (3, 512, 512), IMG_106_den.npy: (1, 64, 64)\n",
      "IMG_107_img.npy: (3, 512, 512), IMG_107_den.npy: (1, 64, 64)\n",
      "IMG_108_img.npy: (3, 512, 512), IMG_108_den.npy: (1, 64, 64)\n",
      "IMG_109_img.npy: (3, 512, 512), IMG_109_den.npy: (1, 64, 64)\n",
      "IMG_10_img.npy: (3, 512, 512), IMG_10_den.npy: (1, 64, 64)\n",
      "IMG_110_img.npy: (3, 512, 512), IMG_110_den.npy: (1, 64, 64)\n",
      "IMG_111_img.npy: (3, 512, 512), IMG_111_den.npy: (1, 64, 64)\n",
      "IMG_112_img.npy: (3, 512, 512), IMG_112_den.npy: (1, 64, 64)\n",
      "IMG_113_img.npy: (3, 512, 512), IMG_113_den.npy: (1, 64, 64)\n",
      "IMG_114_img.npy: (3, 512, 512), IMG_114_den.npy: (1, 64, 64)\n",
      "IMG_115_img.npy: (3, 512, 512), IMG_115_den.npy: (1, 64, 64)\n",
      "IMG_116_img.npy: (3, 512, 512), IMG_116_den.npy: (1, 64, 64)\n",
      "IMG_117_img.npy: (3, 512, 512), IMG_117_den.npy: (1, 64, 64)\n",
      "IMG_118_img.npy: (3, 512, 512), IMG_118_den.npy: (1, 64, 64)\n",
      "IMG_119_img.npy: (3, 512, 512), IMG_119_den.npy: (1, 64, 64)\n",
      "IMG_11_img.npy: (3, 512, 512), IMG_11_den.npy: (1, 64, 64)\n",
      "IMG_120_img.npy: (3, 512, 512), IMG_120_den.npy: (1, 64, 64)\n",
      "IMG_121_img.npy: (3, 512, 512), IMG_121_den.npy: (1, 64, 64)\n",
      "IMG_122_img.npy: (3, 512, 512), IMG_122_den.npy: (1, 64, 64)\n",
      "IMG_123_img.npy: (3, 512, 512), IMG_123_den.npy: (1, 64, 64)\n",
      "IMG_124_img.npy: (3, 512, 512), IMG_124_den.npy: (1, 64, 64)\n",
      "IMG_125_img.npy: (3, 512, 512), IMG_125_den.npy: (1, 64, 64)\n",
      "IMG_126_img.npy: (3, 512, 512), IMG_126_den.npy: (1, 64, 64)\n",
      "IMG_127_img.npy: (3, 512, 512), IMG_127_den.npy: (1, 64, 64)\n",
      "IMG_128_img.npy: (3, 512, 512), IMG_128_den.npy: (1, 64, 64)\n",
      "IMG_129_img.npy: (3, 512, 512), IMG_129_den.npy: (1, 64, 64)\n",
      "IMG_12_img.npy: (3, 512, 512), IMG_12_den.npy: (1, 64, 64)\n",
      "IMG_130_img.npy: (3, 512, 512), IMG_130_den.npy: (1, 64, 64)\n",
      "IMG_131_img.npy: (3, 512, 512), IMG_131_den.npy: (1, 64, 64)\n",
      "IMG_132_img.npy: (3, 512, 512), IMG_132_den.npy: (1, 64, 64)\n",
      "IMG_133_img.npy: (3, 512, 512), IMG_133_den.npy: (1, 64, 64)\n",
      "IMG_134_img.npy: (3, 512, 512), IMG_134_den.npy: (1, 64, 64)\n",
      "IMG_135_img.npy: (3, 512, 512), IMG_135_den.npy: (1, 64, 64)\n",
      "IMG_136_img.npy: (3, 512, 512), IMG_136_den.npy: (1, 64, 64)\n",
      "IMG_137_img.npy: (3, 512, 512), IMG_137_den.npy: (1, 64, 64)\n",
      "IMG_138_img.npy: (3, 512, 512), IMG_138_den.npy: (1, 64, 64)\n",
      "IMG_139_img.npy: (3, 512, 512), IMG_139_den.npy: (1, 64, 64)\n",
      "IMG_13_img.npy: (3, 512, 512), IMG_13_den.npy: (1, 64, 64)\n",
      "IMG_140_img.npy: (3, 512, 512), IMG_140_den.npy: (1, 64, 64)\n",
      "IMG_141_img.npy: (3, 512, 512), IMG_141_den.npy: (1, 64, 64)\n",
      "IMG_142_img.npy: (3, 512, 512), IMG_142_den.npy: (1, 64, 64)\n",
      "IMG_143_img.npy: (3, 512, 512), IMG_143_den.npy: (1, 64, 64)\n",
      "IMG_144_img.npy: (3, 512, 512), IMG_144_den.npy: (1, 64, 64)\n",
      "IMG_145_img.npy: (3, 512, 512), IMG_145_den.npy: (1, 64, 64)\n",
      "IMG_146_img.npy: (3, 512, 512), IMG_146_den.npy: (1, 64, 64)\n",
      "IMG_147_img.npy: (3, 512, 512), IMG_147_den.npy: (1, 64, 64)\n",
      "IMG_148_img.npy: (3, 512, 512), IMG_148_den.npy: (1, 64, 64)\n",
      "IMG_149_img.npy: (3, 512, 512), IMG_149_den.npy: (1, 64, 64)\n",
      "IMG_14_img.npy: (3, 512, 512), IMG_14_den.npy: (1, 64, 64)\n",
      "IMG_150_img.npy: (3, 512, 512), IMG_150_den.npy: (1, 64, 64)\n",
      "IMG_151_img.npy: (3, 512, 512), IMG_151_den.npy: (1, 64, 64)\n",
      "IMG_152_img.npy: (3, 512, 512), IMG_152_den.npy: (1, 64, 64)\n",
      "IMG_153_img.npy: (3, 512, 512), IMG_153_den.npy: (1, 64, 64)\n",
      "IMG_154_img.npy: (3, 512, 512), IMG_154_den.npy: (1, 64, 64)\n",
      "IMG_155_img.npy: (3, 512, 512), IMG_155_den.npy: (1, 64, 64)\n",
      "IMG_156_img.npy: (3, 512, 512), IMG_156_den.npy: (1, 64, 64)\n",
      "IMG_157_img.npy: (3, 512, 512), IMG_157_den.npy: (1, 64, 64)\n",
      "IMG_158_img.npy: (3, 512, 512), IMG_158_den.npy: (1, 64, 64)\n",
      "IMG_159_img.npy: (3, 512, 512), IMG_159_den.npy: (1, 64, 64)\n",
      "IMG_15_img.npy: (3, 512, 512), IMG_15_den.npy: (1, 64, 64)\n",
      "IMG_160_img.npy: (3, 512, 512), IMG_160_den.npy: (1, 64, 64)\n",
      "IMG_161_img.npy: (3, 512, 512), IMG_161_den.npy: (1, 64, 64)\n",
      "IMG_162_img.npy: (3, 512, 512), IMG_162_den.npy: (1, 64, 64)\n",
      "IMG_163_img.npy: (3, 512, 512), IMG_163_den.npy: (1, 64, 64)\n",
      "IMG_164_img.npy: (3, 512, 512), IMG_164_den.npy: (1, 64, 64)\n",
      "IMG_165_img.npy: (3, 512, 512), IMG_165_den.npy: (1, 64, 64)\n",
      "IMG_166_img.npy: (3, 512, 512), IMG_166_den.npy: (1, 64, 64)\n",
      "IMG_167_img.npy: (3, 512, 512), IMG_167_den.npy: (1, 64, 64)\n",
      "IMG_168_img.npy: (3, 512, 512), IMG_168_den.npy: (1, 64, 64)\n",
      "IMG_169_img.npy: (3, 512, 512), IMG_169_den.npy: (1, 64, 64)\n",
      "IMG_16_img.npy: (3, 512, 512), IMG_16_den.npy: (1, 64, 64)\n",
      "IMG_170_img.npy: (3, 512, 512), IMG_170_den.npy: (1, 64, 64)\n",
      "IMG_171_img.npy: (3, 512, 512), IMG_171_den.npy: (1, 64, 64)\n",
      "IMG_172_img.npy: (3, 512, 512), IMG_172_den.npy: (1, 64, 64)\n",
      "IMG_173_img.npy: (3, 512, 512), IMG_173_den.npy: (1, 64, 64)\n",
      "IMG_174_img.npy: (3, 512, 512), IMG_174_den.npy: (1, 64, 64)\n",
      "IMG_175_img.npy: (3, 512, 512), IMG_175_den.npy: (1, 64, 64)\n",
      "IMG_176_img.npy: (3, 512, 512), IMG_176_den.npy: (1, 64, 64)\n",
      "IMG_177_img.npy: (3, 512, 512), IMG_177_den.npy: (1, 64, 64)\n",
      "IMG_178_img.npy: (3, 512, 512), IMG_178_den.npy: (1, 64, 64)\n",
      "IMG_179_img.npy: (3, 512, 512), IMG_179_den.npy: (1, 64, 64)\n",
      "IMG_17_img.npy: (3, 512, 512), IMG_17_den.npy: (1, 64, 64)\n",
      "IMG_180_img.npy: (3, 512, 512), IMG_180_den.npy: (1, 64, 64)\n",
      "IMG_181_img.npy: (3, 512, 512), IMG_181_den.npy: (1, 64, 64)\n",
      "IMG_182_img.npy: (3, 512, 512), IMG_182_den.npy: (1, 64, 64)\n",
      "IMG_183_img.npy: (3, 512, 512), IMG_183_den.npy: (1, 64, 64)\n",
      "IMG_184_img.npy: (3, 512, 512), IMG_184_den.npy: (1, 64, 64)\n",
      "IMG_185_img.npy: (3, 512, 512), IMG_185_den.npy: (1, 64, 64)\n",
      "IMG_186_img.npy: (3, 512, 512), IMG_186_den.npy: (1, 64, 64)\n",
      "IMG_187_img.npy: (3, 512, 512), IMG_187_den.npy: (1, 64, 64)\n",
      "IMG_188_img.npy: (3, 512, 512), IMG_188_den.npy: (1, 64, 64)\n",
      "IMG_189_img.npy: (3, 512, 512), IMG_189_den.npy: (1, 64, 64)\n",
      "IMG_18_img.npy: (3, 512, 512), IMG_18_den.npy: (1, 64, 64)\n",
      "IMG_190_img.npy: (3, 512, 512), IMG_190_den.npy: (1, 64, 64)\n",
      "IMG_191_img.npy: (3, 512, 512), IMG_191_den.npy: (1, 64, 64)\n",
      "IMG_192_img.npy: (3, 512, 512), IMG_192_den.npy: (1, 64, 64)\n",
      "IMG_193_img.npy: (3, 512, 512), IMG_193_den.npy: (1, 64, 64)\n",
      "IMG_194_img.npy: (3, 512, 512), IMG_194_den.npy: (1, 64, 64)\n",
      "IMG_195_img.npy: (3, 512, 512), IMG_195_den.npy: (1, 64, 64)\n",
      "IMG_196_img.npy: (3, 512, 512), IMG_196_den.npy: (1, 64, 64)\n",
      "IMG_197_img.npy: (3, 512, 512), IMG_197_den.npy: (1, 64, 64)\n",
      "IMG_198_img.npy: (3, 512, 512), IMG_198_den.npy: (1, 64, 64)\n",
      "IMG_199_img.npy: (3, 512, 512), IMG_199_den.npy: (1, 64, 64)\n",
      "IMG_19_img.npy: (3, 512, 512), IMG_19_den.npy: (1, 64, 64)\n",
      "IMG_1_img.npy: (3, 512, 512), IMG_1_den.npy: (1, 64, 64)\n",
      "IMG_200_img.npy: (3, 512, 512), IMG_200_den.npy: (1, 64, 64)\n",
      "IMG_201_img.npy: (3, 512, 512), IMG_201_den.npy: (1, 64, 64)\n",
      "IMG_202_img.npy: (3, 512, 512), IMG_202_den.npy: (1, 64, 64)\n",
      "IMG_203_img.npy: (3, 512, 512), IMG_203_den.npy: (1, 64, 64)\n",
      "IMG_204_img.npy: (3, 512, 512), IMG_204_den.npy: (1, 64, 64)\n",
      "IMG_205_img.npy: (3, 512, 512), IMG_205_den.npy: (1, 64, 64)\n",
      "IMG_206_img.npy: (3, 512, 512), IMG_206_den.npy: (1, 64, 64)\n",
      "IMG_207_img.npy: (3, 512, 512), IMG_207_den.npy: (1, 64, 64)\n",
      "IMG_208_img.npy: (3, 512, 512), IMG_208_den.npy: (1, 64, 64)\n",
      "IMG_209_img.npy: (3, 512, 512), IMG_209_den.npy: (1, 64, 64)\n",
      "IMG_20_img.npy: (3, 512, 512), IMG_20_den.npy: (1, 64, 64)\n",
      "IMG_210_img.npy: (3, 512, 512), IMG_210_den.npy: (1, 64, 64)\n",
      "IMG_211_img.npy: (3, 512, 512), IMG_211_den.npy: (1, 64, 64)\n",
      "IMG_212_img.npy: (3, 512, 512), IMG_212_den.npy: (1, 64, 64)\n",
      "IMG_213_img.npy: (3, 512, 512), IMG_213_den.npy: (1, 64, 64)\n",
      "IMG_214_img.npy: (3, 512, 512), IMG_214_den.npy: (1, 64, 64)\n",
      "IMG_215_img.npy: (3, 512, 512), IMG_215_den.npy: (1, 64, 64)\n",
      "IMG_216_img.npy: (3, 512, 512), IMG_216_den.npy: (1, 64, 64)\n",
      "IMG_217_img.npy: (3, 512, 512), IMG_217_den.npy: (1, 64, 64)\n",
      "IMG_218_img.npy: (3, 512, 512), IMG_218_den.npy: (1, 64, 64)\n",
      "IMG_219_img.npy: (3, 512, 512), IMG_219_den.npy: (1, 64, 64)\n",
      "IMG_21_img.npy: (3, 512, 512), IMG_21_den.npy: (1, 64, 64)\n",
      "IMG_220_img.npy: (3, 512, 512), IMG_220_den.npy: (1, 64, 64)\n",
      "IMG_221_img.npy: (3, 512, 512), IMG_221_den.npy: (1, 64, 64)\n",
      "IMG_222_img.npy: (3, 512, 512), IMG_222_den.npy: (1, 64, 64)\n",
      "IMG_223_img.npy: (3, 512, 512), IMG_223_den.npy: (1, 64, 64)\n",
      "IMG_224_img.npy: (3, 512, 512), IMG_224_den.npy: (1, 64, 64)\n",
      "IMG_225_img.npy: (3, 512, 512), IMG_225_den.npy: (1, 64, 64)\n",
      "IMG_226_img.npy: (3, 512, 512), IMG_226_den.npy: (1, 64, 64)\n",
      "IMG_227_img.npy: (3, 512, 512), IMG_227_den.npy: (1, 64, 64)\n",
      "IMG_228_img.npy: (3, 512, 512), IMG_228_den.npy: (1, 64, 64)\n",
      "IMG_229_img.npy: (3, 512, 512), IMG_229_den.npy: (1, 64, 64)\n",
      "IMG_22_img.npy: (3, 512, 512), IMG_22_den.npy: (1, 64, 64)\n",
      "IMG_230_img.npy: (3, 512, 512), IMG_230_den.npy: (1, 64, 64)\n",
      "IMG_231_img.npy: (3, 512, 512), IMG_231_den.npy: (1, 64, 64)\n",
      "IMG_232_img.npy: (3, 512, 512), IMG_232_den.npy: (1, 64, 64)\n",
      "IMG_233_img.npy: (3, 512, 512), IMG_233_den.npy: (1, 64, 64)\n",
      "IMG_234_img.npy: (3, 512, 512), IMG_234_den.npy: (1, 64, 64)\n",
      "IMG_235_img.npy: (3, 512, 512), IMG_235_den.npy: (1, 64, 64)\n",
      "IMG_236_img.npy: (3, 512, 512), IMG_236_den.npy: (1, 64, 64)\n",
      "IMG_237_img.npy: (3, 512, 512), IMG_237_den.npy: (1, 64, 64)\n",
      "IMG_238_img.npy: (3, 512, 512), IMG_238_den.npy: (1, 64, 64)\n",
      "IMG_239_img.npy: (3, 512, 512), IMG_239_den.npy: (1, 64, 64)\n",
      "IMG_23_img.npy: (3, 512, 512), IMG_23_den.npy: (1, 64, 64)\n",
      "IMG_240_img.npy: (3, 512, 512), IMG_240_den.npy: (1, 64, 64)\n",
      "IMG_241_img.npy: (3, 512, 512), IMG_241_den.npy: (1, 64, 64)\n",
      "IMG_242_img.npy: (3, 512, 512), IMG_242_den.npy: (1, 64, 64)\n",
      "IMG_243_img.npy: (3, 512, 512), IMG_243_den.npy: (1, 64, 64)\n",
      "IMG_244_img.npy: (3, 512, 512), IMG_244_den.npy: (1, 64, 64)\n",
      "IMG_245_img.npy: (3, 512, 512), IMG_245_den.npy: (1, 64, 64)\n",
      "IMG_246_img.npy: (3, 512, 512), IMG_246_den.npy: (1, 64, 64)\n",
      "IMG_247_img.npy: (3, 512, 512), IMG_247_den.npy: (1, 64, 64)\n",
      "IMG_248_img.npy: (3, 512, 512), IMG_248_den.npy: (1, 64, 64)\n",
      "IMG_249_img.npy: (3, 512, 512), IMG_249_den.npy: (1, 64, 64)\n",
      "IMG_24_img.npy: (3, 512, 512), IMG_24_den.npy: (1, 64, 64)\n",
      "IMG_250_img.npy: (3, 512, 512), IMG_250_den.npy: (1, 64, 64)\n",
      "IMG_251_img.npy: (3, 512, 512), IMG_251_den.npy: (1, 64, 64)\n",
      "IMG_252_img.npy: (3, 512, 512), IMG_252_den.npy: (1, 64, 64)\n",
      "IMG_253_img.npy: (3, 512, 512), IMG_253_den.npy: (1, 64, 64)\n",
      "IMG_254_img.npy: (3, 512, 512), IMG_254_den.npy: (1, 64, 64)\n",
      "IMG_255_img.npy: (3, 512, 512), IMG_255_den.npy: (1, 64, 64)\n",
      "IMG_256_img.npy: (3, 512, 512), IMG_256_den.npy: (1, 64, 64)\n",
      "IMG_257_img.npy: (3, 512, 512), IMG_257_den.npy: (1, 64, 64)\n",
      "IMG_258_img.npy: (3, 512, 512), IMG_258_den.npy: (1, 64, 64)\n",
      "IMG_259_img.npy: (3, 512, 512), IMG_259_den.npy: (1, 64, 64)\n",
      "IMG_25_img.npy: (3, 512, 512), IMG_25_den.npy: (1, 64, 64)\n",
      "IMG_260_img.npy: (3, 512, 512), IMG_260_den.npy: (1, 64, 64)\n",
      "IMG_261_img.npy: (3, 512, 512), IMG_261_den.npy: (1, 64, 64)\n",
      "IMG_262_img.npy: (3, 512, 512), IMG_262_den.npy: (1, 64, 64)\n",
      "IMG_263_img.npy: (3, 512, 512), IMG_263_den.npy: (1, 64, 64)\n",
      "IMG_264_img.npy: (3, 512, 512), IMG_264_den.npy: (1, 64, 64)\n",
      "IMG_265_img.npy: (3, 512, 512), IMG_265_den.npy: (1, 64, 64)\n",
      "IMG_266_img.npy: (3, 512, 512), IMG_266_den.npy: (1, 64, 64)\n",
      "IMG_267_img.npy: (3, 512, 512), IMG_267_den.npy: (1, 64, 64)\n",
      "IMG_268_img.npy: (3, 512, 512), IMG_268_den.npy: (1, 64, 64)\n",
      "IMG_269_img.npy: (3, 512, 512), IMG_269_den.npy: (1, 64, 64)\n",
      "IMG_26_img.npy: (3, 512, 512), IMG_26_den.npy: (1, 64, 64)\n",
      "IMG_270_img.npy: (3, 512, 512), IMG_270_den.npy: (1, 64, 64)\n",
      "IMG_271_img.npy: (3, 512, 512), IMG_271_den.npy: (1, 64, 64)\n",
      "IMG_272_img.npy: (3, 512, 512), IMG_272_den.npy: (1, 64, 64)\n",
      "IMG_273_img.npy: (3, 512, 512), IMG_273_den.npy: (1, 64, 64)\n",
      "IMG_274_img.npy: (3, 512, 512), IMG_274_den.npy: (1, 64, 64)\n",
      "IMG_275_img.npy: (3, 512, 512), IMG_275_den.npy: (1, 64, 64)\n",
      "IMG_276_img.npy: (3, 512, 512), IMG_276_den.npy: (1, 64, 64)\n",
      "IMG_277_img.npy: (3, 512, 512), IMG_277_den.npy: (1, 64, 64)\n",
      "IMG_278_img.npy: (3, 512, 512), IMG_278_den.npy: (1, 64, 64)\n",
      "IMG_279_img.npy: (3, 512, 512), IMG_279_den.npy: (1, 64, 64)\n",
      "IMG_27_img.npy: (3, 512, 512), IMG_27_den.npy: (1, 64, 64)\n",
      "IMG_280_img.npy: (3, 512, 512), IMG_280_den.npy: (1, 64, 64)\n",
      "IMG_281_img.npy: (3, 512, 512), IMG_281_den.npy: (1, 64, 64)\n",
      "IMG_282_img.npy: (3, 512, 512), IMG_282_den.npy: (1, 64, 64)\n",
      "IMG_283_img.npy: (3, 512, 512), IMG_283_den.npy: (1, 64, 64)\n",
      "IMG_284_img.npy: (3, 512, 512), IMG_284_den.npy: (1, 64, 64)\n",
      "IMG_285_img.npy: (3, 512, 512), IMG_285_den.npy: (1, 64, 64)\n",
      "IMG_286_img.npy: (3, 512, 512), IMG_286_den.npy: (1, 64, 64)\n",
      "IMG_287_img.npy: (3, 512, 512), IMG_287_den.npy: (1, 64, 64)\n",
      "IMG_288_img.npy: (3, 512, 512), IMG_288_den.npy: (1, 64, 64)\n",
      "IMG_289_img.npy: (3, 512, 512), IMG_289_den.npy: (1, 64, 64)\n",
      "IMG_28_img.npy: (3, 512, 512), IMG_28_den.npy: (1, 64, 64)\n",
      "IMG_290_img.npy: (3, 512, 512), IMG_290_den.npy: (1, 64, 64)\n",
      "IMG_291_img.npy: (3, 512, 512), IMG_291_den.npy: (1, 64, 64)\n",
      "IMG_292_img.npy: (3, 512, 512), IMG_292_den.npy: (1, 64, 64)\n",
      "IMG_293_img.npy: (3, 512, 512), IMG_293_den.npy: (1, 64, 64)\n",
      "IMG_294_img.npy: (3, 512, 512), IMG_294_den.npy: (1, 64, 64)\n",
      "IMG_295_img.npy: (3, 512, 512), IMG_295_den.npy: (1, 64, 64)\n",
      "IMG_296_img.npy: (3, 512, 512), IMG_296_den.npy: (1, 64, 64)\n",
      "IMG_297_img.npy: (3, 512, 512), IMG_297_den.npy: (1, 64, 64)\n",
      "IMG_298_img.npy: (3, 512, 512), IMG_298_den.npy: (1, 64, 64)\n",
      "IMG_299_img.npy: (3, 512, 512), IMG_299_den.npy: (1, 64, 64)\n",
      "IMG_29_img.npy: (3, 512, 512), IMG_29_den.npy: (1, 64, 64)\n",
      "IMG_2_img.npy: (3, 512, 512), IMG_2_den.npy: (1, 64, 64)\n",
      "IMG_300_img.npy: (3, 512, 512), IMG_300_den.npy: (1, 64, 64)\n",
      "IMG_30_img.npy: (3, 512, 512), IMG_30_den.npy: (1, 64, 64)\n",
      "IMG_31_img.npy: (3, 512, 512), IMG_31_den.npy: (1, 64, 64)\n",
      "IMG_32_img.npy: (3, 512, 512), IMG_32_den.npy: (1, 64, 64)\n",
      "IMG_33_img.npy: (3, 512, 512), IMG_33_den.npy: (1, 64, 64)\n",
      "IMG_34_img.npy: (3, 512, 512), IMG_34_den.npy: (1, 64, 64)\n",
      "IMG_35_img.npy: (3, 512, 512), IMG_35_den.npy: (1, 64, 64)\n",
      "IMG_36_img.npy: (3, 512, 512), IMG_36_den.npy: (1, 64, 64)\n",
      "IMG_37_img.npy: (3, 512, 512), IMG_37_den.npy: (1, 64, 64)\n",
      "IMG_38_img.npy: (3, 512, 512), IMG_38_den.npy: (1, 64, 64)\n",
      "IMG_39_img.npy: (3, 512, 512), IMG_39_den.npy: (1, 64, 64)\n",
      "IMG_3_img.npy: (3, 512, 512), IMG_3_den.npy: (1, 64, 64)\n",
      "IMG_40_img.npy: (3, 512, 512), IMG_40_den.npy: (1, 64, 64)\n",
      "IMG_41_img.npy: (3, 512, 512), IMG_41_den.npy: (1, 64, 64)\n",
      "IMG_42_img.npy: (3, 512, 512), IMG_42_den.npy: (1, 64, 64)\n",
      "IMG_43_img.npy: (3, 512, 512), IMG_43_den.npy: (1, 64, 64)\n",
      "IMG_44_img.npy: (3, 512, 512), IMG_44_den.npy: (1, 64, 64)\n",
      "IMG_45_img.npy: (3, 512, 512), IMG_45_den.npy: (1, 64, 64)\n",
      "IMG_46_img.npy: (3, 512, 512), IMG_46_den.npy: (1, 64, 64)\n",
      "IMG_47_img.npy: (3, 512, 512), IMG_47_den.npy: (1, 64, 64)\n",
      "IMG_48_img.npy: (3, 512, 512), IMG_48_den.npy: (1, 64, 64)\n",
      "IMG_49_img.npy: (3, 512, 512), IMG_49_den.npy: (1, 64, 64)\n",
      "IMG_4_img.npy: (3, 512, 512), IMG_4_den.npy: (1, 64, 64)\n",
      "IMG_50_img.npy: (3, 512, 512), IMG_50_den.npy: (1, 64, 64)\n",
      "IMG_51_img.npy: (3, 512, 512), IMG_51_den.npy: (1, 64, 64)\n",
      "IMG_52_img.npy: (3, 512, 512), IMG_52_den.npy: (1, 64, 64)\n",
      "IMG_53_img.npy: (3, 512, 512), IMG_53_den.npy: (1, 64, 64)\n",
      "IMG_54_img.npy: (3, 512, 512), IMG_54_den.npy: (1, 64, 64)\n",
      "IMG_55_img.npy: (3, 512, 512), IMG_55_den.npy: (1, 64, 64)\n",
      "IMG_56_img.npy: (3, 512, 512), IMG_56_den.npy: (1, 64, 64)\n",
      "IMG_57_img.npy: (3, 512, 512), IMG_57_den.npy: (1, 64, 64)\n",
      "IMG_58_img.npy: (3, 512, 512), IMG_58_den.npy: (1, 64, 64)\n",
      "IMG_59_img.npy: (3, 512, 512), IMG_59_den.npy: (1, 64, 64)\n",
      "IMG_5_img.npy: (3, 512, 512), IMG_5_den.npy: (1, 64, 64)\n",
      "IMG_60_img.npy: (3, 512, 512), IMG_60_den.npy: (1, 64, 64)\n",
      "IMG_61_img.npy: (3, 512, 512), IMG_61_den.npy: (1, 64, 64)\n",
      "IMG_62_img.npy: (3, 512, 512), IMG_62_den.npy: (1, 64, 64)\n",
      "IMG_63_img.npy: (3, 512, 512), IMG_63_den.npy: (1, 64, 64)\n",
      "IMG_64_img.npy: (3, 512, 512), IMG_64_den.npy: (1, 64, 64)\n",
      "IMG_65_img.npy: (3, 512, 512), IMG_65_den.npy: (1, 64, 64)\n",
      "IMG_66_img.npy: (3, 512, 512), IMG_66_den.npy: (1, 64, 64)\n",
      "IMG_67_img.npy: (3, 512, 512), IMG_67_den.npy: (1, 64, 64)\n",
      "IMG_68_img.npy: (3, 512, 512), IMG_68_den.npy: (1, 64, 64)\n",
      "IMG_69_img.npy: (3, 512, 512), IMG_69_den.npy: (1, 64, 64)\n",
      "IMG_6_img.npy: (3, 512, 512), IMG_6_den.npy: (1, 64, 64)\n",
      "IMG_70_img.npy: (3, 512, 512), IMG_70_den.npy: (1, 64, 64)\n",
      "IMG_71_img.npy: (3, 512, 512), IMG_71_den.npy: (1, 64, 64)\n",
      "IMG_72_img.npy: (3, 512, 512), IMG_72_den.npy: (1, 64, 64)\n",
      "IMG_73_img.npy: (3, 512, 512), IMG_73_den.npy: (1, 64, 64)\n",
      "IMG_74_img.npy: (3, 512, 512), IMG_74_den.npy: (1, 64, 64)\n",
      "IMG_75_img.npy: (3, 512, 512), IMG_75_den.npy: (1, 64, 64)\n",
      "IMG_76_img.npy: (3, 512, 512), IMG_76_den.npy: (1, 64, 64)\n",
      "IMG_77_img.npy: (3, 512, 512), IMG_77_den.npy: (1, 64, 64)\n",
      "IMG_78_img.npy: (3, 512, 512), IMG_78_den.npy: (1, 64, 64)\n",
      "IMG_79_img.npy: (3, 512, 512), IMG_79_den.npy: (1, 64, 64)\n",
      "IMG_7_img.npy: (3, 512, 512), IMG_7_den.npy: (1, 64, 64)\n",
      "IMG_80_img.npy: (3, 512, 512), IMG_80_den.npy: (1, 64, 64)\n",
      "IMG_81_img.npy: (3, 512, 512), IMG_81_den.npy: (1, 64, 64)\n",
      "IMG_82_img.npy: (3, 512, 512), IMG_82_den.npy: (1, 64, 64)\n",
      "IMG_83_img.npy: (3, 512, 512), IMG_83_den.npy: (1, 64, 64)\n",
      "IMG_84_img.npy: (3, 512, 512), IMG_84_den.npy: (1, 64, 64)\n",
      "IMG_85_img.npy: (3, 512, 512), IMG_85_den.npy: (1, 64, 64)\n",
      "IMG_86_img.npy: (3, 512, 512), IMG_86_den.npy: (1, 64, 64)\n",
      "IMG_87_img.npy: (3, 512, 512), IMG_87_den.npy: (1, 64, 64)\n",
      "IMG_88_img.npy: (3, 512, 512), IMG_88_den.npy: (1, 64, 64)\n",
      "IMG_89_img.npy: (3, 512, 512), IMG_89_den.npy: (1, 64, 64)\n",
      "IMG_8_img.npy: (3, 512, 512), IMG_8_den.npy: (1, 64, 64)\n",
      "IMG_90_img.npy: (3, 512, 512), IMG_90_den.npy: (1, 64, 64)\n",
      "IMG_91_img.npy: (3, 512, 512), IMG_91_den.npy: (1, 64, 64)\n",
      "IMG_92_img.npy: (3, 512, 512), IMG_92_den.npy: (1, 64, 64)\n",
      "IMG_93_img.npy: (3, 512, 512), IMG_93_den.npy: (1, 64, 64)\n",
      "IMG_94_img.npy: (3, 512, 512), IMG_94_den.npy: (1, 64, 64)\n",
      "IMG_95_img.npy: (3, 512, 512), IMG_95_den.npy: (1, 64, 64)\n",
      "IMG_96_img.npy: (3, 512, 512), IMG_96_den.npy: (1, 64, 64)\n",
      "IMG_97_img.npy: (3, 512, 512), IMG_97_den.npy: (1, 64, 64)\n",
      "IMG_98_img.npy: (3, 512, 512), IMG_98_den.npy: (1, 64, 64)\n",
      "IMG_99_img.npy: (3, 512, 512), IMG_99_den.npy: (1, 64, 64)\n",
      "IMG_9_img.npy: (3, 512, 512), IMG_9_den.npy: (1, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "data_dir = r\"C:\\Users\\sneha\\.cache\\kagglehub\\datasets\\tthien\\shanghaitech\\versions\\1\\ShanghaiTech\\part_A\\train_data\\processed_fixed\"\n",
    "\n",
    "img_files = sorted([f for f in os.listdir(data_dir) if f.endswith(\"_img.npy\")])\n",
    "den_files = sorted([f for f in os.listdir(data_dir) if f.endswith(\"_den.npy\")])\n",
    "\n",
    "for img_file, den_file in zip(img_files, den_files):\n",
    "    img = np.load(os.path.join(data_dir, img_file))\n",
    "    den = np.load(os.path.join(data_dir, den_file))\n",
    "    print(f\"{img_file}: {img.shape}, {den_file}: {den.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
