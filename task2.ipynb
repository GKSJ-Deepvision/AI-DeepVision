{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yysosOEjobzS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4fb8a34-f56f-426d-cb02-4987c8aa1266"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mdmxKBjdoefS"
      },
      "outputs": [],
      "source": [
        "# ImageNet normalization\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "R3wsDmHoohl_"
      },
      "outputs": [],
      "source": [
        "class CSRNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        vgg = models.vgg16_bn(weights=models.VGG16_BN_Weights.IMAGENET1K_V1)\n",
        "\n",
        "        self.frontend = nn.Sequential(*list(vgg.features.children())[:33])\n",
        "\n",
        "        self.backend = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, 3, padding=2, dilation=2), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, 3, padding=2, dilation=2), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, 3, padding=2, dilation=2), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 256, 3, padding=2, dilation=2), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 128, 3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 1, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.frontend(x)\n",
        "        x = self.backend(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twWWPyETojsP",
        "outputId": "d63d9fd8-f59b-4ca3-f9c1-871f12a34f6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 528M/528M [00:02<00:00, 196MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ CSRNet model loaded successfully\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = CSRNet().to(device)\n",
        "model.load_state_dict(\n",
        "    torch.load(\n",
        "        \"/content/drive/MyDrive/deepvision/checkpoints/best_finetuned.pth\",\n",
        "        map_location=device\n",
        "    )\n",
        ")\n",
        "model.eval()\n",
        "\n",
        "print(\"‚úÖ CSRNet model loaded successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hIp4T2KonIV",
        "outputId": "2e0d23ad-48c8-45bf-e347-575ed5ba87d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Video loaded\n"
          ]
        }
      ],
      "source": [
        "INPUT_VIDEO = \"/content/drive/MyDrive/deepvision/video.mp4\"\n",
        "OUTPUT_VIDEO = \"/content/drive/MyDrive/deepvision/output.mp4\"\n",
        "\n",
        "THRESHOLD = 12\n",
        "\n",
        "os.makedirs(\"/content/drive/MyDrive/deepvision\", exist_ok=True)\n",
        "\n",
        "cap = cv2.VideoCapture(INPUT_VIDEO)\n",
        "\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(OUTPUT_VIDEO, fourcc, fps, (width, height))\n",
        "\n",
        "print(\"‚úÖ Video loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAHSIM5fooUr",
        "outputId": "6af6a46e-9331-42d3-d98f-9a14908e2a15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Video Frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 331/331 [00:15<00:00, 21.27frame/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Processing complete\n",
            "üìÅ Output saved at: /content/drive/MyDrive/deepvision/output.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "frame_count = 0\n",
        "\n",
        "with tqdm(\n",
        "    total=total_frames,\n",
        "    desc=\"Processing Video Frames\",\n",
        "    unit=\"frame\"\n",
        ") as pbar:\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "        # Convert frame to PIL\n",
        "        img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "        img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "        # Inference\n",
        "        with torch.no_grad():\n",
        "            density_map = model(img_tensor)\n",
        "\n",
        "        density_map = torch.relu(density_map)\n",
        "        count = int(round(density_map.sum().item()))\n",
        "        count = max(0, count)\n",
        "\n",
        "        # Alert logic\n",
        "        if count > THRESHOLD:\n",
        "            alert_text = \"ALERT: Crowd Limit Exceeded\"\n",
        "            color = (0, 0, 255)\n",
        "        else:\n",
        "            alert_text = \"Crowd Level Safe\"\n",
        "            color = (0, 255, 0)\n",
        "\n",
        "        # Draw text\n",
        "        cv2.putText(frame, f\"Count: {count}\", (20, 40),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
        "\n",
        "        cv2.putText(frame, alert_text, (20, 80),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
        "\n",
        "        out.write(frame)\n",
        "        pbar.update(1)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "print(\"\\n‚úÖ Processing complete\")\n",
        "print(\"üìÅ Output saved at:\", OUTPUT_VIDEO)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}