{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b093237d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:10<00:00, 27.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ TrainA preprocessing complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.io import loadmat\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =========================\n",
    "# PATHS\n",
    "# =========================\n",
    "DATA_ROOT = Path(\"Dataset/ShanghaiTech/part_A/train_data\")\n",
    "IMG_DIR = DATA_ROOT / \"images\"\n",
    "GT_DIR  = DATA_ROOT / \"ground-truth\"\n",
    "\n",
    "SAVE_DIR = Path(\"preprocessed/TrainA\")\n",
    "IMG_SAVE = SAVE_DIR / \"images\"\n",
    "GT_SAVE  = SAVE_DIR / \"gt\"\n",
    "\n",
    "IMG_SAVE.mkdir(parents=True, exist_ok=True)\n",
    "GT_SAVE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# CONSTANTS\n",
    "# =========================\n",
    "TARGET_SIZE = (512, 512)\n",
    "GT_SIZE = (64, 64)\n",
    "\n",
    "def make_density_map(points, shape):\n",
    "    h, w = shape\n",
    "    density = np.zeros((h, w), np.float32)\n",
    "    for x, y in points:\n",
    "        if 0 <= int(x) < w and 0 <= int(y) < h:\n",
    "            density[int(y), int(x)] = 1.0\n",
    "    density = gaussian_filter(density, sigma=4)\n",
    "    return density\n",
    "\n",
    "# =========================\n",
    "# PREPROCESS LOOP\n",
    "# =========================\n",
    "for img_path in tqdm(sorted(IMG_DIR.glob(\"*.jpg\"))):\n",
    "    name = img_path.stem\n",
    "\n",
    "    # Load image\n",
    "    img = cv2.imread(str(img_path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, TARGET_SIZE).astype(np.float32) / 255.0\n",
    "    img_tensor = torch.tensor(img).permute(2,0,1)\n",
    "\n",
    "    # Load GT\n",
    "    mat = loadmat(str(GT_DIR / f\"GT_{name}.mat\"))\n",
    "    points = mat[\"image_info\"][0][0][0][0][0]\n",
    "\n",
    "    # Density map\n",
    "    den = make_density_map(points, TARGET_SIZE)\n",
    "\n",
    "    # Downsample for CSRNet\n",
    "    den_small = cv2.resize(den, GT_SIZE) * 64\n",
    "    den_tensor = torch.tensor(den_small).unsqueeze(0)\n",
    "\n",
    "    # SAVE (MATCH DATASET LOADER)\n",
    "    torch.save(img_tensor, IMG_SAVE / f\"{name}.pt\")\n",
    "    torch.save(den_tensor, GT_SAVE / f\"{name}.pt\")\n",
    "\n",
    "print(\"✔ TrainA preprocessing complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
