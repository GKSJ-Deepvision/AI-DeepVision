{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea30ec02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (0.24.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: ultralytics in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (8.3.236)\n",
      "Requirement already satisfied: supervision in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (0.27.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from ultralytics) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from ultralytics) (2.32.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from ultralytics) (1.16.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from ultralytics) (7.1.3)\n",
      "Requirement already satisfied: polars>=0.20.0 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from ultralytics) (1.36.1)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.18 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from ultralytics) (2.0.18)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from supervision) (0.7.1)\n",
      "Requirement already satisfied: tqdm>=4.62.3 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from supervision) (4.67.1)\n",
      "Requirement already satisfied: polars-runtime-32==1.36.1 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from polars>=0.20.0->ultralytics) (1.36.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from tqdm>=4.62.3->supervision) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\acepc\\desktop\\deepvision crowd monitoring\\venv\\lib\\site-packages (from jinja2->torch) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (if not already installed)\n",
    "!pip install torch torchvision opencv-python matplotlib ultralytics supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "711d1af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from pathlib import Path\n",
    "from matplotlib import cm\n",
    "from collections import defaultdict\n",
    "from ultralytics import YOLO\n",
    "import supervision as sv\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Configuration\n",
    "MODEL_PATH = r\"C:\\Users\\ACEPC\\Desktop\\DeepVision Crowd Monitoring\\models\\best_crowd_counter_unified.pth\"\n",
    "ALERT_THRESHOLD = 30  # Adjust based on your needs\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ImageNet normalization\n",
    "IMAGENET_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "IMAGENET_STD = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "577c64e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODEL ARCHITECTURE\n",
    "# ============================================================================\n",
    "\n",
    "def create_csrnet():\n",
    "    \"\"\"Create CSRNet model architecture\"\"\"\n",
    "    print(\"Building CSRNet architecture...\")\n",
    "    \n",
    "    vgg = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "    features = list(vgg.features.children())\n",
    "    \n",
    "    frontend = nn.Sequential(*features[0:23])\n",
    "    \n",
    "    backend = nn.Sequential(\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=1, dilation=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=2, dilation=2),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=4, dilation=4),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(512, 256, kernel_size=3, padding=1, dilation=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(256, 128, kernel_size=3, padding=1, dilation=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(128, 1, kernel_size=1, padding=0),\n",
    "    )\n",
    "    \n",
    "    model = nn.Sequential(frontend, backend)\n",
    "    print(\"‚úì CSRNet architecture created\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def load_trained_model(model_path, device=DEVICE):\n",
    "    \"\"\"Load trained CSRNet model\"\"\"\n",
    "    print(f\"Loading CSRNet from: {model_path}\")\n",
    "    \n",
    "    model = create_csrnet()\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    \n",
    "    if 'model_state' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['model_state'])\n",
    "        print(f\"‚úì Loaded checkpoint from epoch {checkpoint.get('epoch', 'unknown')}\")\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint)\n",
    "        print(\"‚úì Loaded model weights\")\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"‚úì CSRNet ready on {device}\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14c8f5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PERSON TRACKER\n",
    "# ============================================================================\n",
    "\n",
    "class PersonTracker:\n",
    "    \"\"\"Multi-object tracker to prevent re-counting\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tracker = sv.ByteTrack(\n",
    "            track_activation_threshold=0.25,\n",
    "            lost_track_buffer=30,\n",
    "            minimum_matching_threshold=0.8,\n",
    "            frame_rate=30\n",
    "        )\n",
    "        \n",
    "        self.unique_ids = set()\n",
    "        self.track_history = defaultdict(list)\n",
    "        \n",
    "    def update(self, detections):\n",
    "        \"\"\"Update tracker with new detections\"\"\"\n",
    "        tracked_detections = self.tracker.update_with_detections(detections)\n",
    "        \n",
    "        if tracked_detections.tracker_id is not None:\n",
    "            for track_id in tracked_detections.tracker_id:\n",
    "                self.unique_ids.add(int(track_id))\n",
    "        \n",
    "        return tracked_detections\n",
    "    \n",
    "    def get_total_unique_count(self):\n",
    "        \"\"\"Get total unique people seen\"\"\"\n",
    "        return len(self.unique_ids)\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset tracker\"\"\"\n",
    "        self.tracker = sv.ByteTrack(\n",
    "            track_activation_threshold=0.25,\n",
    "            lost_track_buffer=30,\n",
    "            minimum_matching_threshold=0.8,\n",
    "            frame_rate=30\n",
    "        )\n",
    "        self.unique_ids = set()\n",
    "        self.track_history.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a1b0d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ENHANCED CROWD COUNTER\n",
    "# ============================================================================\n",
    "\n",
    "class EnhancedCrowdCounter:\n",
    "    \"\"\"Enhanced counter with detection + tracking + density\"\"\"\n",
    "    \n",
    "    def __init__(self, csrnet_model, device=DEVICE, csrnet_input_size=(512, 512)):\n",
    "        self.csrnet = csrnet_model\n",
    "        self.device = device\n",
    "        self.mean = IMAGENET_MEAN\n",
    "        self.std = IMAGENET_STD\n",
    "        \n",
    "        # CSRNet input size (Height, Width) - MUST match training size!\n",
    "        # Your training: 512x512 with downsample factor 8\n",
    "        self.csrnet_input_size = csrnet_input_size\n",
    "        print(f\"‚úì CSRNet will process images at: {csrnet_input_size[0]}x{csrnet_input_size[1]}\")\n",
    "        print(f\"  (Matches training TARGET_SIZE)\")\n",
    "        \n",
    "        # Load YOLOv8\n",
    "        print(\"Loading YOLOv8 person detector...\")\n",
    "        self.yolo = YOLO('yolov8n.pt')\n",
    "        print(\"‚úì YOLOv8 loaded\")\n",
    "        \n",
    "        # Initialize tracker\n",
    "        self.tracker = PersonTracker()\n",
    "        \n",
    "        # Annotators\n",
    "        self.box_annotator = sv.BoxAnnotator(thickness=2)\n",
    "        self.trace_annotator = sv.TraceAnnotator(thickness=2, trace_length=50)\n",
    "    \n",
    "    def preprocess_frame(self, frame):\n",
    "        \"\"\"Preprocess frame for CSRNet - resize to training size\"\"\"\n",
    "        # Resize to CSRNet training size\n",
    "        frame_resized = cv2.resize(frame, \n",
    "                                   (self.csrnet_input_size[1], self.csrnet_input_size[0]), \n",
    "                                   interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Convert BGR to RGB\n",
    "        img_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Normalize\n",
    "        img_normalized = img_rgb.astype(np.float32) / 255.0\n",
    "        img_normalized = (img_normalized - self.mean) / self.std\n",
    "        \n",
    "        # Convert to tensor\n",
    "        img_tensor = torch.from_numpy(img_normalized).permute(2, 0, 1).unsqueeze(0)\n",
    "        img_tensor = img_tensor.to(self.device, dtype=torch.float32)\n",
    "        \n",
    "        return img_tensor\n",
    "    \n",
    "    def predict_density(self, frame):\n",
    "        \"\"\"Get density map from CSRNet\"\"\"\n",
    "        with torch.no_grad():\n",
    "            img_tensor = self.preprocess_frame(frame)\n",
    "            density_map = self.csrnet(img_tensor)\n",
    "            density_np = density_map.squeeze().cpu().numpy()\n",
    "            count = float(density_np.sum())\n",
    "        return density_np, count\n",
    "    \n",
    "    def detect_people(self, frame):\n",
    "        \"\"\"Detect people using YOLOv8\"\"\"\n",
    "        results = self.yolo(frame, classes=[0], verbose=False)[0]\n",
    "        detections = sv.Detections.from_ultralytics(results)\n",
    "        return detections\n",
    "    \n",
    "    def predict_with_tracking(self, frame):\n",
    "        \"\"\"Complete prediction pipeline\"\"\"\n",
    "        # Detect people\n",
    "        detections = self.detect_people(frame)\n",
    "        \n",
    "        # Track people\n",
    "        tracked_detections = self.tracker.update(detections)\n",
    "        \n",
    "        # Get counts\n",
    "        detection_count = len(tracked_detections)\n",
    "        unique_count = self.tracker.get_total_unique_count()\n",
    "        \n",
    "        # Get density map\n",
    "        density_map, density_count = self.predict_density(frame)\n",
    "        \n",
    "        # Annotate frame\n",
    "        annotated_frame = frame.copy()\n",
    "        \n",
    "        # Draw bounding boxes and IDs\n",
    "        if len(tracked_detections) > 0:\n",
    "            # Draw boxes\n",
    "            annotated_frame = self.box_annotator.annotate(\n",
    "                scene=annotated_frame,\n",
    "                detections=tracked_detections\n",
    "            )\n",
    "            \n",
    "            # Draw tracking traces\n",
    "            annotated_frame = self.trace_annotator.annotate(\n",
    "                scene=annotated_frame,\n",
    "                detections=tracked_detections\n",
    "            )\n",
    "            \n",
    "            # Draw labels manually\n",
    "            if tracked_detections.tracker_id is not None:\n",
    "                for bbox, track_id in zip(tracked_detections.xyxy, tracked_detections.tracker_id):\n",
    "                    x1, y1, x2, y2 = map(int, bbox)\n",
    "                    label = f\"ID:{track_id}\"\n",
    "                    \n",
    "                    # Draw label background\n",
    "                    label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]\n",
    "                    cv2.rectangle(annotated_frame, \n",
    "                                (x1, y1 - label_size[1] - 10), \n",
    "                                (x1 + label_size[0] + 10, y1), \n",
    "                                (0, 255, 0), -1)\n",
    "                    \n",
    "                    # Draw label text\n",
    "                    cv2.putText(annotated_frame, label, \n",
    "                              (x1 + 5, y1 - 5), \n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)\n",
    "        \n",
    "        return annotated_frame, density_map, detection_count, unique_count, density_count\n",
    "    \n",
    "    def create_heatmap_overlay(self, density_map, original_frame, alpha=0.4):\n",
    "        \"\"\"Create density heatmap overlay\"\"\"\n",
    "        h, w = original_frame.shape[:2]\n",
    "        density_resized = cv2.resize(density_map, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        density_max = density_resized.max()\n",
    "        if density_max > 0:\n",
    "            density_normalized = density_resized / density_max\n",
    "        else:\n",
    "            density_normalized = density_resized\n",
    "        \n",
    "        heatmap = cm.jet(density_normalized)[:, :, :3]\n",
    "        heatmap = (heatmap * 255).astype(np.uint8)\n",
    "        \n",
    "        overlay = cv2.addWeighted(original_frame, 1-alpha, heatmap, alpha, 0)\n",
    "        \n",
    "        return overlay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff38125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LIVE WEBCAM PROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "def draw_info_panel(frame, det_count, unique_count, density_count, fps, is_alert):\n",
    "    \"\"\"Draw information panel on frame\"\"\"\n",
    "    # Create semi-transparent background\n",
    "    overlay = frame.copy()\n",
    "    h, w = frame.shape[:2]\n",
    "    \n",
    "    # Top panel\n",
    "    cv2.rectangle(overlay, (0, 0), (w, 180), (0, 0, 0), -1)\n",
    "    cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)\n",
    "    \n",
    "    # Title\n",
    "    cv2.putText(frame, \"CSRNet Crowd Counter - Live Feed\", \n",
    "                (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "    \n",
    "    # Alert status\n",
    "    if is_alert:\n",
    "        alert_text = f\"ALERT! Count: {det_count} > Threshold: {ALERT_THRESHOLD}\"\n",
    "        color = (0, 0, 255)  # Red\n",
    "    else:\n",
    "        alert_text = f\"Normal - Count: {det_count}\"\n",
    "        color = (0, 255, 0)  # Green\n",
    "    \n",
    "    cv2.putText(frame, alert_text, \n",
    "                (10, 65), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "    \n",
    "    # Statistics\n",
    "    stats_y = 100\n",
    "    stats = [\n",
    "        f\"Detected: {det_count} people\",\n",
    "        f\"Unique Tracked: {unique_count} people\",\n",
    "        f\"Density Estimate: {int(density_count)}\",\n",
    "        f\"FPS: {fps:.1f}\"\n",
    "    ]\n",
    "    \n",
    "    for i, stat in enumerate(stats):\n",
    "        cv2.putText(frame, stat, \n",
    "                   (10, stats_y + i*25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    \n",
    "    # Instructions at bottom\n",
    "    cv2.putText(frame, \"Press 'Q' to quit | 'R' to reset tracking | 'S' to save frame\", \n",
    "                (10, h - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "\n",
    "def run_webcam_detection(counter, camera_index=0):\n",
    "    \"\"\"Run live webcam detection\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STARTING LIVE WEBCAM DETECTION\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Camera Index: {camera_index}\")\n",
    "    print(f\"Alert Threshold: {ALERT_THRESHOLD}\")\n",
    "    print(\"\\nControls:\")\n",
    "    print(\"  Q - Quit\")\n",
    "    print(\"  R - Reset tracking\")\n",
    "    print(\"  S - Save current frame\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # Open webcam\n",
    "    cap = cv2.VideoCapture(camera_index)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"‚ùå Error: Cannot access webcam!\")\n",
    "        print(\"\\nTroubleshooting:\")\n",
    "        print(\"  1. Check if another application is using the webcam\")\n",
    "        print(\"  2. Try different camera_index: 0, 1, 2...\")\n",
    "        print(\"  3. Check camera permissions\")\n",
    "        return\n",
    "    \n",
    "    # Set camera properties\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "    \n",
    "    print(\"‚úì Webcam opened successfully\")\n",
    "    print(\"‚úì Starting detection loop...\\n\")\n",
    "    \n",
    "    # Statistics tracking\n",
    "    frame_count = 0\n",
    "    detection_counts = []\n",
    "    density_counts = []\n",
    "    fps_list = []\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Read frame\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"‚ùå Failed to grab frame\")\n",
    "                break\n",
    "            \n",
    "            frame_count += 1\n",
    "            \n",
    "            # Process frame\n",
    "            annotated, density_map, det_count, unique_count, dens_count = counter.predict_with_tracking(frame)\n",
    "            \n",
    "            # Create heatmap overlay\n",
    "            overlay = counter.create_heatmap_overlay(density_map, annotated, alpha=0.3)\n",
    "            \n",
    "            # Update statistics\n",
    "            detection_counts.append(det_count)\n",
    "            density_counts.append(dens_count)\n",
    "            \n",
    "            # Keep last 100 frames\n",
    "            if len(detection_counts) > 100:\n",
    "                detection_counts.pop(0)\n",
    "                density_counts.pop(0)\n",
    "            \n",
    "            # Calculate FPS\n",
    "            fps = 1.0 / (time.time() - start_time)\n",
    "            fps_list.append(fps)\n",
    "            if len(fps_list) > 30:\n",
    "                fps_list.pop(0)\n",
    "            avg_fps = np.mean(fps_list)\n",
    "            \n",
    "            # Check alert\n",
    "            is_alert = det_count > ALERT_THRESHOLD\n",
    "            \n",
    "            # Draw info panel\n",
    "            display_frame = draw_info_panel(overlay, det_count, unique_count, \n",
    "                                          dens_count, avg_fps, is_alert)\n",
    "            \n",
    "            # Display\n",
    "            cv2.imshow('CSRNet Crowd Counter - Live', display_frame)\n",
    "            \n",
    "            # Keyboard controls\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            \n",
    "            if key == ord('q') or key == ord('Q'):\n",
    "                print(\"\\n‚úì Quitting...\")\n",
    "                break\n",
    "            \n",
    "            elif key == ord('r') or key == ord('R'):\n",
    "                print(\"\\nüîÑ Resetting tracker...\")\n",
    "                counter.tracker.reset()\n",
    "                detection_counts.clear()\n",
    "                density_counts.clear()\n",
    "                print(\"‚úì Tracker reset complete\")\n",
    "            \n",
    "            elif key == ord('s') or key == ord('S'):\n",
    "                filename = f\"crowd_capture_{frame_count}.jpg\"\n",
    "                cv2.imwrite(filename, display_frame)\n",
    "                print(f\"‚úì Frame saved: {filename}\")\n",
    "            \n",
    "            # Print stats every 30 frames\n",
    "            if frame_count % 30 == 0:\n",
    "                avg_det = np.mean(detection_counts) if detection_counts else 0\n",
    "                max_det = max(detection_counts) if detection_counts else 0\n",
    "                print(f\"Frame {frame_count} | Det: {det_count} | Unique: {unique_count} | \"\n",
    "                      f\"Avg: {avg_det:.1f} | Max: {max_det} | FPS: {avg_fps:.1f}\")\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚úì Interrupted by user\")\n",
    "    \n",
    "    finally:\n",
    "        # Cleanup\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        # Final statistics\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"SESSION SUMMARY\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Total Frames Processed: {frame_count}\")\n",
    "        print(f\"Total Unique People: {unique_count}\")\n",
    "        if detection_counts:\n",
    "            print(f\"Average Detection: {np.mean(detection_counts):.1f}\")\n",
    "            print(f\"Max Detection: {max(detection_counts)}\")\n",
    "        if fps_list:\n",
    "            print(f\"Average FPS: {np.mean(fps_list):.1f}\")\n",
    "        print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cb184d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üöÄ CSRNet CROWD COUNTER - WEBCAM TESTING\n",
      "============================================================\n",
      "\n",
      "‚úì Model file found: best_crowd_counter_unified.pth\n",
      "‚úì File size: 185.33 MB\n",
      "\n",
      "============================================================\n",
      "LOADING MODELS\n",
      "============================================================\n",
      "Loading CSRNet from: C:\\Users\\ACEPC\\Desktop\\DeepVision Crowd Monitoring\\models\\best_crowd_counter_unified.pth\n",
      "Building CSRNet architecture...\n",
      "‚úì CSRNet architecture created\n",
      "‚úì Loaded checkpoint from epoch 191\n",
      "‚úì CSRNet ready on cpu\n",
      "‚úì CSRNet will process images at: 512x512\n",
      "  (Matches training TARGET_SIZE)\n",
      "Loading YOLOv8 person detector...\n",
      "‚úì YOLOv8 loaded\n",
      "\n",
      "‚úì All models loaded successfully!\n",
      "‚úì Ready to start webcam detection\n",
      "\n",
      "\n",
      "============================================================\n",
      "STARTING LIVE WEBCAM DETECTION\n",
      "============================================================\n",
      "Camera Index: 0\n",
      "Alert Threshold: 30\n",
      "\n",
      "Controls:\n",
      "  Q - Quit\n",
      "  R - Reset tracking\n",
      "  S - Save current frame\n",
      "============================================================\n",
      "\n",
      "‚úì Webcam opened successfully\n",
      "‚úì Starting detection loop...\n",
      "\n",
      "\n",
      "‚úì Interrupted by user\n",
      "\n",
      "============================================================\n",
      "SESSION SUMMARY\n",
      "============================================================\n",
      "Total Frames Processed: 26\n",
      "Total Unique People: 2\n",
      "Average Detection: 1.2\n",
      "Max Detection: 2\n",
      "Average FPS: 0.2\n",
      "============================================================\n",
      "\n",
      "‚úì Program terminated successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*60)\n",
    "    print(\"üöÄ CSRNet CROWD COUNTER - WEBCAM TESTING\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Check if model exists\n",
    "    model_path = Path(MODEL_PATH)\n",
    "    \n",
    "    if not model_path.exists():\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"‚ö†Ô∏è  MODEL FILE NOT FOUND\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Expected path: {MODEL_PATH}\")\n",
    "        print(f\"\\nThe models directory exists at:\")\n",
    "        print(f\"  {model_path.parent}\")\n",
    "        print(f\"\\nBut the model file doesn't exist yet.\")\n",
    "        print(\"\\nüìù NEXT STEPS:\")\n",
    "        print(\"  1. Train your CSRNet model first\")\n",
    "        print(\"  2. Save the trained model to the path above\")\n",
    "        print(\"  3. The saved file should be named: best_crowd_counter_unified.pth\")\n",
    "        print(\"  4. Then run this script again\")\n",
    "        print(\"\\nüí° TIP: Make sure your training script saves the model like this:\")\n",
    "        print(\"     torch.save(model.state_dict(), MODEL_PATH)\")\n",
    "        print(\"     or\")\n",
    "        print(\"     torch.save({'model_state': model.state_dict(), 'epoch': epoch}, MODEL_PATH)\")\n",
    "        print(\"=\"*60)\n",
    "        sys.exit(1)\n",
    "    \n",
    "    print(f\"\\n‚úì Model file found: {model_path.name}\")\n",
    "    print(f\"‚úì File size: {model_path.stat().st_size / (1024*1024):.2f} MB\")\n",
    "    \n",
    "    try:\n",
    "        # Load CSRNet\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"LOADING MODELS\")\n",
    "        print(\"=\"*60)\n",
    "        csrnet = load_trained_model(MODEL_PATH)\n",
    "        \n",
    "        # Create enhanced counter\n",
    "        counter = EnhancedCrowdCounter(\n",
    "            csrnet, \n",
    "            csrnet_input_size=(512, 512)  # ‚úÖ Matches your training: 512x512 (H, W)\n",
    "        )\n",
    "        \n",
    "        print(\"\\n‚úì All models loaded successfully!\")\n",
    "        print(\"‚úì Ready to start webcam detection\\n\")\n",
    "        \n",
    "        # Run webcam detection\n",
    "        run_webcam_detection(counter, camera_index=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        sys.exit(1)\n",
    "    \n",
    "    print(\"\\n‚úì Program terminated successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
