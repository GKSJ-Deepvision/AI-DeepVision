{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf1ef441",
   "metadata": {},
   "source": [
    "PREPROCESSING \n",
    "   1. Optional cleaning\n",
    "   2. Converting BGR->RGB\n",
    "   3. Resizing\n",
    "   4. Normalization\n",
    "   5. Converting to tensor\n",
    "   6. Loading .mat files\n",
    "   7. Generating density maps \n",
    "   8. Downsampling the density map\n",
    "   9. Converting to tensor\n",
    "   10. Saving the .pt files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acd38a72",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msio\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gaussian_filter\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567f3ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RAW_IMG_DIR = Path(r\"C:\\Users\\mahal\\OneDrive\\Desktop\\DL\\archive\\ShanghaiTech\\part_A\\train_data\\images\")\n",
    "RAW_GT_DIR  = Path(r\"C:\\Users\\mahal\\OneDrive\\Desktop\\DL\\archive\\ShanghaiTech\\part_A\\train_data\\ground-truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a270fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_IMG_TORCH_DIR = Path(r\"C:\\Users\\mahal\\OneDrive\\Desktop\\DL\\torch_images_trainA\")\n",
    "OUT_GT_TORCH_DIR  = Path(r\"C:\\Users\\mahal\\OneDrive\\Desktop\\DL\\torch_density_trainA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d751a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_W, TARGET_H = 512, 512\n",
    "DOWNSAMPLE_FACTOR = 8\n",
    "GAUSSIAN_SIGMA = 4\n",
    "CLEAN_METHOD = \"none\"        # \"none\", \"denoise\", \"clahe\", \"denoise+clahe\"\n",
    "NORMALIZE_METHOD = \"imagenet\" # \"imagenet\" recommended\n",
    "IMAGENET_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "IMAGENET_STD  = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n",
    "# ----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e27506",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_IMG_TORCH_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_GT_TORCH_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0b77e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  robust mat reader\n",
    "def read_points_from_mat(mat_path):\n",
    "    \"\"\"\n",
    "    Robust reader for ShanghaiTech-style GT .mat files.\n",
    "    Returns Nx2 float32 array of (x,y) points or empty array if nothing found.\n",
    "    \"\"\"\n",
    "    mat = sio.loadmat(mat_path)\n",
    "    # if common 'image_info' key exists try multiple nestings\n",
    "    if \"image_info\" in mat:\n",
    "        info = mat[\"image_info\"]\n",
    "        # try several common access patterns\n",
    "        candidates = []\n",
    "        try:\n",
    "            candidates.append(info[0][0][0][0])\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            candidates.append(info[0][0][0][0][0])\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            candidates.append(info[0][0])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        for cand in candidates:\n",
    "            if isinstance(cand, np.ndarray) and cand.ndim == 2 and cand.shape[1] == 2:\n",
    "                return cand.astype(np.float32)\n",
    "            if isinstance(cand, np.ndarray) and cand.dtype == object:\n",
    "                for item in cand.ravel():\n",
    "                    if isinstance(item, np.ndarray) and item.ndim == 2 and item.shape[1] == 2:\n",
    "                        return item.astype(np.float32)\n",
    "\n",
    "    # fallback: scan all keys for a 2-column numeric array or inside object arrays\n",
    "    for k, v in mat.items():\n",
    "        if isinstance(v, np.ndarray) and v.ndim == 2 and v.shape[1] == 2:\n",
    "            return v.astype(np.float32)\n",
    "        if isinstance(v, np.ndarray) and v.dtype == object:\n",
    "            for item in v.ravel():\n",
    "                if isinstance(item, np.ndarray) and item.ndim == 2 and item.shape[1] == 2:\n",
    "                    return item.astype(np.float32)\n",
    "\n",
    "    # nothing found\n",
    "    return np.zeros((0, 2), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833740d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional cleaning \n",
    "def denoise(img_bgr):\n",
    "    return cv2.fastNlMeansDenoisingColored(img_bgr, None, 10, 10, 7, 21)\n",
    "def clahe(img_bgr):\n",
    "    ycrcb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2YCrCb)\n",
    "    y, cr, cb = cv2.split(ycrcb)\n",
    "    c = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    y2 = c.apply(y)\n",
    "    merged = cv2.merge((y2, cr, cb))\n",
    "    return cv2.cvtColor(merged, cv2.COLOR_YCrCb2BGR)\n",
    "def clean_image(img_bgr, method):\n",
    "    if method == \"none\":\n",
    "        return img_bgr\n",
    "    if method == \"denoise\":\n",
    "        return denoise(img_bgr)\n",
    "    if method == \"clahe\":\n",
    "        return clahe(img_bgr)\n",
    "    if method == \"denoise+clahe\":\n",
    "        return clahe(denoise(img_bgr))\n",
    "    return img_bgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71a8def",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# helpers \n",
    "def list_images(folder):\n",
    "    return sorted([p.name for p in folder.iterdir() if p.suffix.lower() in EXTS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4691b4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image_rgb(img_rgb, method=NORMALIZE_METHOD):\n",
    "    img = img_rgb.astype(np.float32) / 255.0\n",
    "    if method == \"imagenet\":\n",
    "        return (img - IMAGENET_MEAN) / IMAGENET_STD\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d859f08",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generate_density_map(img_h, img_w, points, sigma=GAUSSIAN_SIGMA):\n",
    "    density = np.zeros((img_h, img_w), dtype=np.float32)\n",
    "    for p in points:\n",
    "        x = int(min(img_w - 1, max(0, round(p[0]))))\n",
    "        y = int(min(img_h - 1, max(0, round(p[1]))))\n",
    "        density[y, x] += 1.0\n",
    "    density = gaussian_filter(density, sigma=sigma)\n",
    "    return density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27398aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_density(density, factor):\n",
    "    H, W = density.shape\n",
    "    new_h, new_w = H // factor, W // factor\n",
    "    if new_h <= 0 or new_w <= 0:\n",
    "        raise ValueError(\"Downsample factor too large for density size.\")\n",
    "    small = cv2.resize(density, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "    small = small * (factor * factor)  # preserve counts\n",
    "    return small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac46a2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main preprocessing\n",
    "def preprocess_save_torch(\n",
    "    raw_img_dir=RAW_IMG_DIR,\n",
    "    raw_gt_dir=RAW_GT_DIR,\n",
    "    out_img_torch_dir=OUT_IMG_TORCH_DIR,\n",
    "    out_gt_torch_dir=OUT_GT_TORCH_DIR,\n",
    "    target_w=TARGET_W,\n",
    "    target_h=TARGET_H,\n",
    "    clean_method=CLEAN_METHOD,\n",
    "    normalize_method=NORMALIZE_METHOD,\n",
    "    downsample_factor=DOWNSAMPLE_FACTOR\n",
    "):\n",
    "    img_files = list_images(raw_img_dir)\n",
    "    print(f\"Found {len(img_files)} images in {raw_img_dir}\")\n",
    "\n",
    "    for i, fname in enumerate(img_files, 1):\n",
    "        base = os.path.splitext(fname)[0]\n",
    "        img_path = raw_img_dir / fname\n",
    "\n",
    "        # try GT filename patterns used by ShanghaiTech\n",
    "        gt_path1 = raw_gt_dir / f\"GT_{base}.mat\"\n",
    "        gt_path2 = raw_gt_dir / f\"{base}.mat\"\n",
    "        gt_path = gt_path1 if gt_path1.exists() else (gt_path2 if gt_path2.exists() else None)\n",
    "\n",
    "        if gt_path is None:\n",
    "            print(f\"[{i}/{len(img_files)}] Missing GT for {fname} (expected {gt_path1.name} or {gt_path2.name}) -> skipping\")\n",
    "            continue\n",
    "\n",
    "        img_bgr = cv2.imread(str(img_path))\n",
    "        if img_bgr is None:\n",
    "            print(f\"[{i}/{len(img_files)}] Failed to read image {img_path} -> skipping\")\n",
    "            continue\n",
    "\n",
    "        orig_h, orig_w = img_bgr.shape[:2]\n",
    "        sx = target_w / float(orig_w)\n",
    "        sy = target_h / float(orig_h)\n",
    "\n",
    "        # optional cleaning\n",
    "        img_bgr = clean_image(img_bgr, clean_method)\n",
    "\n",
    "        # resize\n",
    "        resized_bgr = cv2.resize(img_bgr, (target_w, target_h), interpolation=cv2.INTER_AREA)\n",
    "        resized_rgb = cv2.cvtColor(resized_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # normalize\n",
    "        img_norm = normalize_image_rgb(resized_rgb, method=normalize_method)\n",
    "\n",
    "        # to torch tensor [C,H,W]\n",
    "        img_t = torch.from_numpy(img_norm.astype(np.float32)).permute(2, 0, 1).contiguous()\n",
    "\n",
    "        # read points robustly and resize them to target\n",
    "        pts = read_points_from_mat(str(gt_path))\n",
    "        if pts.size != 0:\n",
    "            pts_resized = pts.copy()\n",
    "            pts_resized[:, 0] = pts[:, 0] * sx\n",
    "            pts_resized[:, 1] = pts[:, 1] * sy\n",
    "        else:\n",
    "            pts_resized = pts\n",
    "\n",
    "        # generate density full-res and downsample\n",
    "        density_full = generate_density_map(target_h, target_w, pts_resized, sigma=GAUSSIAN_SIGMA)\n",
    "        density_down = downsample_density(density_full, downsample_factor)\n",
    "\n",
    "        # to torch density tensor [1, H_down, W_down]\n",
    "        dens_t = torch.from_numpy(density_down.astype(np.float32)).unsqueeze(0).contiguous()\n",
    "\n",
    "        # save .pt files\n",
    "        img_out = out_img_torch_dir / (base + \".pt\")\n",
    "        gt_out  = out_gt_torch_dir  / (base + \".pt\")\n",
    "        torch.save(img_t, str(img_out))\n",
    "        torch.save(dens_t, str(gt_out))\n",
    "\n",
    "        print(f\"[{i}/{len(img_files)}] Saved {base}  pts:{pts_resized.shape[0]}  img:{img_t.shape} gt:{dens_t.shape}\")\n",
    "\n",
    "    print(\"\\nâœ” Preprocessing completed.\")\n",
    "    print(\"Images saved to:\", out_img_torch_dir)\n",
    "    print(\"GTs saved to   :\", out_gt_torch_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d51219",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run preprocessing\n",
    "    preprocess_save_torch()\n",
    "\n",
    "\n",
    "    # Get one .pt file from the output directory\n",
    "    sample_files = list(OUT_IMG_TORCH_DIR.glob(\"*.pt\"))\n",
    "    \n",
    "    if len(sample_files) == 0:\n",
    "        print(\"No .pt files found in output directory.\")\n",
    "    else:\n",
    "        sample_path = sample_files[0]  # take the first .pt file\n",
    "        base = sample_path.stem\n",
    "        \n",
    "        # Load saved tensors\n",
    "        img_t = torch.load(OUT_IMG_TORCH_DIR / f\"{base}.pt\")\n",
    "        gt_t  = torch.load(OUT_GT_TORCH_DIR  / f\"{base}.pt\")\n",
    "\n",
    "        # Print shapes\n",
    "        print(\"\\n=== SHAPE CHECK ===\")\n",
    "        print(\"Image tensor shape :\", img_t.shape)    # [3, H, W]\n",
    "        print(\"GT density shape   :\", gt_t.shape)     # [1, H_down, W_down]\n",
    "        print(\"Sample file        :\", base)\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
